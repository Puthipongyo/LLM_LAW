import os
import re
import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from huggingface_hub import HfFolder
import pytrec_eval


os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
torch.cuda.empty_cache()


model_name = "scb10x/llama3.1-typhoon2-70b-instruct"
token = HfFolder.get_token()

quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)

tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, token=token)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quant_config,
    device_map="auto",
    torch_dtype=torch.float16,
    token=token
)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢
def ask_law_question(question, context):
    messages = [
        {"role": "system", "content": """ 
        ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏û‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå
        ‡∏à‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏î‡∏µ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ "‡πÄ‡∏•‡∏Ç‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏û‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå" ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 5 ‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡πÅ‡∏£‡∏Å ‡∏ó‡∏µ‡πà‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÄ‡πÄ‡∏•‡∏∞‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≠‡∏° ‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢ ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 5 ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏°‡∏≤‡∏ï‡∏£‡∏≤"
        ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ ‡πÄ‡∏ä‡πà‡∏ô: 1336, 1299, 1520, 1500, 1337
        """},
        {"role": "user", "content": f"""
        ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:\n{context}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:\n{question}
        """},
    ]

    input_ids = tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        return_tensors="pt"
    ).to(model.device)

    terminators = [
        tokenizer.eos_token_id,
        tokenizer.convert_tokens_to_ids("<|eot_id|>")
    ]

    outputs = model.generate(
        input_ids,
        max_new_tokens=256,
        eos_token_id=terminators,
        do_sample=False,
        temperature=0.7,
        top_p=0.95,
    )
    response = outputs[0][input_ids.shape[-1]:]
    decoded = tokenizer.decode(response, skip_special_tokens=True)

    return decoded.strip()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡∏Ç‡∏°‡∏≤‡∏ï‡∏£‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô 1336
def extract_law_numbers(text):
    return re.findall(r'\d+', text)

def evaluate_with_pytrec(df, k=5):
    qrel = {}  # ground truth
    run = {}   # predicted

    for idx, row in df.iterrows():
        qid = f"q{idx}"
        true_ids = extract_law_numbers(str(row['answers']))
        pred_ids = extract_law_numbers(str(row['predicted_law']))[:k]

        qrel[qid] = {law_id: 1 for law_id in true_ids}

        run[qid] = {law_id: 1.0 / (i + 1) for i, law_id in enumerate(pred_ids)}

    evaluator = pytrec_eval.RelevanceEvaluator(qrel, {'recall'})
    results = evaluator.evaluate(run)


    per_row_recalls = []
    for qid, metrics in results.items():
        row_idx = int(qid[1:])
        recall_score = metrics.get(f'recall_{k}', 0.0)
        df.at[row_idx, 'recall_at_k'] = recall_score
        per_row_recalls.append(recall_score)

    average_recall = sum(per_row_recalls) / len(per_row_recalls) if per_row_recalls else 0.0
    return average_recall

# Main process
if __name__ == "__main__":
    df = pd.read_csv("/workspace/test/data_case_100.csv", encoding="utf-8-sig")

    if "text" not in df.columns or "answers" not in df.columns:
        raise ValueError("CSV ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ column 'text' ‡πÅ‡∏•‡∏∞ 'answers'")

    df['predicted_law'] = ""

    for i in range(df.shape[0]):
        context = df['text'].iloc[i]
        # context = f"{question}"

        full_prompt = f"""
        ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏î‡∏µ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡πÅ‡∏û‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á 
        """.strip()

        ans = ask_law_question(full_prompt, context)
        df.at[i, 'predicted_law'] = ans
        print(f"[{i}] ‚úÖ Answer: {ans}")

        if i == 50:  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏Ñ‡πà 3 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
            break

    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Recall@5
    df_eval = df.head(50)
    recall_k = evaluate_with_pytrec(df_eval, k=5)


    print(f"\nüéØ Recall@5 (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å {len(df_eval)} ‡πÅ‡∏ñ‡∏ß): {recall_k:.4f}")

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•
    df_eval.to_csv("/workspace/test/output_predicted.csv", index=False, encoding="utf-8-sig")
